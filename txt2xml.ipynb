{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# txt2xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import glob\n",
    "from PIL import Image\n",
    " \n",
    "# VEDAI 图像存储位置\n",
    "src_img_dir = r\"G:\\zhenyu\\data\\1x1_all_ng_img\"\n",
    "# VEDAI 图像的 ground truth 的 txt 文件存放位置\n",
    "src_txt_dir = r\"G:\\zhenyu\\data\\1x1_label\\1x1_all_ng_txt\\txt\"\n",
    "src_xml_dir = r\"G:\\zhenyu\\VOC2007\\Annotations\"\n",
    " \n",
    "img_Lists = glob.glob(src_img_dir + '/*.bmp')\n",
    " \n",
    "img_basenames = [] # e.g. 100.jpg\n",
    "for item in img_Lists:\n",
    "    img_basenames.append(os.path.basename(item))\n",
    " \n",
    "img_names = [] # e.g. 100\n",
    "for item in img_basenames:\n",
    "    temp1, temp2 = os.path.splitext(item)\n",
    "    img_names.append(temp1)\n",
    " \n",
    "for img in img_names:\n",
    "    im = Image.open((src_img_dir + '/' + img + '.bmp'))\n",
    "    width, height = im.size\n",
    " \n",
    "    # open the crospronding txt file\n",
    "    gt = open(src_txt_dir + '/' + img + '.txt').read().splitlines()\n",
    "    #gt = open(src_txt_dir + '/gt_' + img + '.txt').read().splitlines()\n",
    " \n",
    "    # write in xml file\n",
    "    #os.mknod(src_xml_dir + '/' + img + '.xml')\n",
    "    xml_file = open((src_xml_dir + '/' + img + '.xml'), 'w')\n",
    "    xml_file.write('<annotation>\\n')\n",
    "    xml_file.write('    <folder>VOC2007</folder>\\n')\n",
    "    xml_file.write('    <filename>' + str(img) + '.bmp' + '</filename>\\n')\n",
    "    xml_file.write('    <size>\\n')\n",
    "    xml_file.write('        <width>' + str(width) + '</width>\\n')\n",
    "    xml_file.write('        <height>' + str(height) + '</height>\\n')\n",
    "    xml_file.write('        <depth>3</depth>\\n')\n",
    "    xml_file.write('    </size>\\n')\n",
    " \n",
    "    # write the region of image on xml file\n",
    "    for img_each_label in gt:\n",
    "        spt = img_each_label.split(' ') #这里如果txt里面是以逗号‘，’隔开的，那么就改为spt = img_each_label.split(',')。\n",
    "        xml_file.write('    <object>\\n')\n",
    "        xml_file.write('        <name>' + str(spt[0]) + '</name>\\n')\n",
    "        xml_file.write('        <pose>Unspecified</pose>\\n')\n",
    "        xml_file.write('        <truncated>0</truncated>\\n')\n",
    "        xml_file.write('        <difficult>0</difficult>\\n')\n",
    "        xml_file.write('        <bndbox>\\n')\n",
    "        xml_file.write('            <xmin>' + str(spt[1]) + '</xmin>\\n')\n",
    "        xml_file.write('            <ymin>' + str(spt[2]) + '</ymin>\\n')\n",
    "        xml_file.write('            <xmax>' + str(spt[3]) + '</xmax>\\n')\n",
    "        xml_file.write('            <ymax>' + str(spt[4]) + '</ymax>\\n')\n",
    "        xml_file.write('        </bndbox>\\n')\n",
    "        xml_file.write('    </object>\\n')\n",
    " \n",
    "    xml_file.write('</annotation>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    " \n",
    "trainval_percent = 0.85\n",
    "train_percent = 0.9\n",
    "xmlfilepath=r'G:\\zhenyu\\voc\\Annotations'\n",
    "txtsavepath=r\"G:\\zhenyu\\voc\\ImageSets\\Main\"\n",
    "total_xml = os.listdir(xmlfilepath)\n",
    " \n",
    "num=len(total_xml)\n",
    "num_list=range(num)\n",
    "tv=int(num*trainval_percent)\n",
    "tr=int(tv*train_percent)\n",
    "trainval= random.sample(list,tv)\n",
    "train=random.sample(trainval,tr)\n",
    " \n",
    "ftrainval = open(r'G:\\zhenyu\\voc\\ImageSets\\Main\\trainval.txt', 'w')\n",
    "ftest = open(r'G:\\zhenyu\\voc\\ImageSets\\Main\\test.txt', 'w')\n",
    "ftrain = open(r'G:\\zhenyu\\voc\\ImageSets\\Main\\train.txt', 'w')\n",
    "fval = open(r'G:\\zhenyu\\voc\\ImageSets\\Main\\val.txt', 'w')\n",
    " \n",
    "for i  in num_list:\n",
    "    name=total_xml[i][:-4]+'\\n'\n",
    "    if i in trainval:\n",
    "        ftrainval.write(name)\n",
    "        if i in train:\n",
    "            ftrain.write(name)\n",
    "        else:\n",
    "            fval.write(name)\n",
    "    else:\n",
    "        ftest.write(name)\n",
    " \n",
    "ftrainval.close()\n",
    "ftrain.close()\n",
    "fval.close()\n",
    "ftest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## readxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys,random\n",
    "import cv2\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def load_xmlfile(xml_dir,xml_name,img_dir):\n",
    "    \"\"\"\n",
    "    Load image and bounding boxes info from XML file in the PASCAL VOC\n",
    "    format.\n",
    "    \"\"\"\n",
    "\n",
    "    imgname = xml_name.replace(\".xml\", \".bmp\")\n",
    "    xml_name=os.path.join(xml_dir, xml_name)\n",
    "    print(xml_name)\n",
    "    tree = ET.parse(xml_name)\n",
    "    objs = tree.findall('object')\n",
    "    num_objs = len(objs)\n",
    "    print(xml_name,os.path.join(img_dir, imgname))\n",
    "    image = cv2.imread(os.path.join(img_dir, imgname),1)\n",
    "    #image = gammer(image,0.5)\n",
    "    boxes = np.zeros((num_objs, 4), dtype=np.uint16)\n",
    "    gt_classes = list()\n",
    "    rect_list = list()\n",
    "    # Load object bounding boxes into a data frame.\n",
    "    for ix, obj in enumerate(objs):\n",
    "        bbox = obj.find('bndbox')\n",
    "        # Make pixel indexes 0-based\n",
    "        #print (x1)\n",
    "        x1 = float(bbox.find('xmin').text)\n",
    "        y1 = float(bbox.find('ymin').text)\n",
    "        x2 = float(bbox.find('xmax').text)\n",
    "        y2 = float(bbox.find('ymax').text)\n",
    "        cls = obj.find('name').text.strip()\n",
    "        #cls = class_to_ind[obj.find('name').text.strip()]\n",
    "        rect = [x1, y1, x2, y2]\n",
    "        cv2.rectangle(image,(int(x1),int(y1)),(int(x2),int(y2)),(0,128,0),1)\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        cv.putText(image, str(cls), (int(x1),int(y1)), font, 1, (255, 255, 255), 1)\n",
    "        rect_list.append(rect)\n",
    "        gt_classes.append(cls)\n",
    "    savedir= \"./gt_d/\"\n",
    "    if not os.path.exists(savedir):\n",
    "        os.makedirs(savedir)\n",
    "    cv2.imwrite(savedir+imgname,image)\n",
    "    #cv2.waitKey(0)\n",
    "    return rect_list, gt_classes\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    xml_dir = \"G:\\zhenyu\\VOC2007\\Annotations\"\n",
    "    xml_name = \"SK_QFN_DY_P01_FM_20190318_131447-crop_03404_00663_03711_00968.xml\"\n",
    "    img_dir = \"G:\\zhenyu\\VOC2007\\JPEGImages\"\n",
    "    load_xmlfile(xml_dir, xml_name, img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "train_percent = 0.8\n",
    "\n",
    "imgfilepath = r'G:\\zhenyu\\VOC2007\\JPEGImages'\n",
    "xmlfilepath=r'G:\\zhenyu\\VOC2007\\Annotations'\n",
    "\n",
    "train_xml_path=r\"G:\\zhenyu\\VOC2007\\train\\ann\"\n",
    "train_img_path = r\"G:\\zhenyu\\VOC2007\\train\\img\"\n",
    "test_xml_path=r\"G:\\zhenyu\\VOC2007\\test\\ann\"\n",
    "test_img_path=r\"G:\\zhenyu\\VOC2007\\test\\img\"\n",
    "\n",
    "total_xml = os.listdir(xmlfilepath)\n",
    "\n",
    "num=len(total_xml)\n",
    "\n",
    "num_list=range(num)\n",
    "\n",
    "tr =int(num * train_percent)\n",
    "\n",
    "train = random.sample(num_list,tr)\n",
    "\n",
    "for i in range(num):\n",
    "    if i in train:\n",
    "        shutil.move(os.path.join(xmlfilepath,total_xml[i]), train_xml_path)\n",
    "        shutil.move(os.path.join(imgfilepath,os.path.splitext(total_xml[i])[0] + \".bmp\" ), train_img_path)\n",
    "    else:\n",
    "        shutil.move(os.path.join(xmlfilepath,total_xml[i]), test_xml_path)\n",
    "        shutil.move(os.path.join(imgfilepath, os.path.splitext(total_xml[i])[0] + \".bmp\"), test_img_path)\n",
    "\n",
    "\n",
    "# ftrainval = open(r'G:\\zhenyu\\voc\\ImageSets\\Main\\trainval.txt', 'w')\n",
    "# ftest = open(r'G:\\zhenyu\\voc\\ImageSets\\Main\\test.txt', 'w')\n",
    "# ftrain = open(r'G:\\zhenyu\\voc\\ImageSets\\Main\\train.txt', 'w')\n",
    "# fval = open(r'G:\\zhenyu\\voc\\ImageSets\\Main\\val.txt', 'w')\n",
    " \n",
    "# for i  in list:\n",
    "#     name=total_xml[i][:-4]+'\\n'\n",
    "#     if i in trainval:\n",
    "#         ftrainval.write(name)\n",
    "#         if i in train:\n",
    "#             ftrain.write(name)\n",
    "#         else:\n",
    "#             fval.write(name)\n",
    "#     else:\n",
    "#         ftest.write(name)\n",
    " \n",
    "# ftrainval.close()\n",
    "# ftrain.close()\n",
    "# fval.close()\n",
    "# ftest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
